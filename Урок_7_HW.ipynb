{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W7u-73y5f5g"
   },
   "source": [
    "Здравствуйте.\n",
    "\n",
    "Spark умеет валидировать модели. Попробуем это сделать. Evaluation ипортируется следующим образом:\n",
    "\n",
    "\n",
    "```\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "```\n",
    "\n",
    "В частности [RegressionEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html#pyspark.ml.evaluation.RegressionEvaluator.metricName)\n",
    "\n",
    "# Задание\n",
    "Ниже обучается и оцениваться модель. \n",
    "\n",
    "Нужно перевести этот в Pipeline (вам понадобится VectorAssembler), а затем оценить MAE с помощью spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wH9YYYd9yHM6"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sW4oDIDPw5Dd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes, load_iris, load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[2]\")\\\n",
    "    .appName(\"Lesson_2\")\\\n",
    "    .config(\"spark.executor.instances\",2)\\\n",
    "    .config(\"spark.executor.memory\",'2g')\\\n",
    "    .config(\"spark.executor.cores\",1)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9wpYw5zUxBzv"
   },
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "dataset = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "dataset['target'] = data['target']\n",
    "\n",
    "cols_to_vector = F.udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "spark_dataset = spark.createDataFrame(dataset).select(cols_to_vector(F.array(*data['feature_names'])).alias('features'), 'target').cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#посмотрим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'target']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|[0.00632,18.0,2.3...|  24.0|\n",
      "|[0.02731,0.0,7.07...|  21.6|\n",
      "|[0.02729,0.0,7.07...|  34.7|\n",
      "|[0.03237,0.0,2.18...|  33.4|\n",
      "|[0.06905,0.0,2.18...|  36.2|\n",
      "|[0.02985,0.0,2.18...|  28.7|\n",
      "|[0.08829,12.5,7.8...|  22.9|\n",
      "|[0.14455,12.5,7.8...|  27.1|\n",
      "|[0.21124,12.5,7.8...|  16.5|\n",
      "|[0.17004,12.5,7.8...|  18.9|\n",
      "|[0.22489,12.5,7.8...|  15.0|\n",
      "|[0.11747,12.5,7.8...|  18.9|\n",
      "|[0.09378,12.5,7.8...|  21.7|\n",
      "|[0.62976,0.0,8.14...|  20.4|\n",
      "|[0.63796,0.0,8.14...|  18.2|\n",
      "|[0.62739,0.0,8.14...|  19.9|\n",
      "|[1.05393,0.0,8.14...|  23.1|\n",
      "|[0.7842,0.0,8.14,...|  17.5|\n",
      "|[0.80271,0.0,8.14...|  20.2|\n",
      "|[0.7258,0.0,8.14,...|  18.2|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "HYdMGKWaxqsI"
   },
   "outputs": [],
   "source": [
    "train, test = spark_dataset.randomSplit([0.7, 0.3])\n",
    "rfr = RandomForestRegressor(featuresCol='features',labelCol='target')\n",
    "rfr = rfr.fit(train)\n",
    "train_predictions = rfr.transform(train)\n",
    "test_predictions = rfr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features|target|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|[0.00632,18.0,2.3...|  24.0| 26.43339806943908|\n",
      "|[0.01311,90.0,1.2...|  35.4| 33.50688736263736|\n",
      "|[0.01381,80.0,0.4...|  50.0| 45.76861155812786|\n",
      "|[0.01778,95.0,1.4...|  32.9|  32.2933906063743|\n",
      "|[0.02009,95.0,2.6...|  50.0| 47.18409165401236|\n",
      "|[0.02187,60.0,2.9...|  31.1| 29.84822910494832|\n",
      "|[0.02729,0.0,7.07...|  34.7| 35.40151893939394|\n",
      "|[0.02763,75.0,2.9...|  30.8|29.560764873904226|\n",
      "|[0.02875,28.0,15....|  25.0| 24.72409075260569|\n",
      "|[0.0315,95.0,1.47...|  34.9|31.104085549166836|\n",
      "|[0.03237,0.0,2.18...|  33.4| 36.47886487776929|\n",
      "|[0.03359,75.0,2.9...|  34.9| 33.78507954545454|\n",
      "|[0.0351,95.0,2.68...|  48.5| 46.84239720956792|\n",
      "|[0.03584,80.0,3.3...|  23.5|25.550332204206207|\n",
      "|[0.03659,25.0,4.8...|  24.8| 24.03220558375607|\n",
      "|[0.04011,80.0,1.5...|  33.3|33.214039415898114|\n",
      "|[0.04203,28.0,15....|  22.9|23.583519908174782|\n",
      "|[0.04294,28.0,15....|  20.6|21.069491094736566|\n",
      "|[0.04462,25.0,4.8...|  23.9| 23.53092620324181|\n",
      "|[0.0456,0.0,13.89...|  23.3|20.721996340150085|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUBg1pAR3dpT",
    "outputId": "0d91a044-9a66-4256-bd02-887706d9cd7d"
   },
   "outputs": [],
   "source": [
    "# Заменить нужно эту часть\n",
    "\n",
    "# pandas_train_predictions = train_predictions.toPandas()\n",
    "# pandas_test_predictions = test_predictions.toPandas()\n",
    "\n",
    "# print(f'''\n",
    "#     Scores:: \n",
    "#         train: {mean_absolute_error(\n",
    "#             pandas_train_predictions.target, \n",
    "#             pandas_train_predictions.prediction)}, \n",
    "#         test: {mean_absolute_error(\n",
    "#             pandas_test_predictions.target, \n",
    "#             pandas_test_predictions.prediction)}\n",
    "#     ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction',\n",
    "    labelCol='target',\n",
    "    metricName='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.92"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(evaluator.evaluate(train_predictions),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ответ: средняя абсолютная ошибка - 1.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Урок 7.  HW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
